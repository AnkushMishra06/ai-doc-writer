# Dataset Design Specification

## Purpose
This document specifies the structure, requirements, constraints, and sources for the dataset used to train and evaluate the AI-powered documentation generation system. The objective is to ensure consistency, prevent data leakage and enable reproducible evaluation

## Dataset Requirements
The dataset must contain examples of Python source code paired with corresponding human-written documentation. The goal is to build a supervised learning corpus for conditional text generation.

### Required dataset properties
- Sufficient diversity in code complexity, including simple and complex functions
- Well-structured docstrings written by people
- No autogenerated documentation or extracted comments without natural language structure
- Open-source origin with appropriate licenses
- Variety of programming constructs such as classes, methods, and free functions

### Data motivation
Accurate documentation generation requires examples demonstrating:
- How parameters and return values are described
- How behavior is expressed in natural language
- Consistent docstring structure patterns

## Dataset Structure
Each dataset entry represents a single documentable code unit, such as a function or class. The dataset will be represented in structured JSON format to support both training and evaluation workflows.

### Required fields per sample
- file_path: path to the source file
- code_entity_type: function or a class
- entity_name: name of function or a class depending on code_entity_type
- parameters: list of parameter names extracted from the function signature
- return_type: if specified or inferable from the code
- code_block: the source code definition associated with the documentation
- docstring_reference: the ground truth documentation written by a human

These fields ensure that each training sample contains sufficient information for generation models and evaluation logic.

## Dataset Sources
The dataset will be constructed using publicly available Python repos that include human-written docstrings. The sources must satisfy the following conditions:
- Licensed under permissive open-source licenses (MIT, Apache 2.0, BSD)
- Contain significant volumes of documented functions
- Represent a diversity of coding styles and structures
- Avoid auto-generated documentation

Potential dataset sources include:
- GitHub repositories
- Python standard library modules with docstrings
- Popular open-source Python packages

## Data Leakage Prevention Strategy
Data leakage is a major risk in documentation generation systems because code units within the same repository or module may share stylistic, structural, or semantic patterns. To prevent leakage between training and evaluation stages, dataset splits will follow these constraints:
- Train/validation/test splits will be performed at the repository or module level rather than at the function/class level.
- Code entities from the same source file will not be divided across multiple splits.
- Repository metadata will be logged to ensure traceability.

Splitting by code entity would risk memorizing documentation style patterns present within the same repository, resulting in artificially inflated evaluation performance and reduced generalizability.

## Ground Truth Documentation Definition
Ground truth documentation refers to the human-authored docstrings present in source code. The dataset will extract only documentation that satisfies the following criteria:
- Written manually by a human contributor
- Attached directly to the code entity (function, class, or method)
- Located in docstring format (triple-quoted string immediately following the definition)
- Expressed in natural language rather than generated from static code comments

### Exclusions
This does not qualify as ground truth:
- Auto-generated documentation comments
- Inline comments that do not follow docstring conventions
- Documentation copied or mirrored from external sources without modification
- Generated documentation from LLMs or templates

### Rationale
Only human-authored docstrings are used as ground truth to avoid label contamination and to ensure that the model learns from authentic examples of developer-written documentation. This constraint prevents evaluation inflation when generated or templated sources are accidentally included.

## Dataset Split Strategy
The dataset will be divided into training, validation, and test sets using repository-level splitting to eliminate cross-contamination of documentation style and implementation patterns.
Split ratios:
- Training: 70%
- Validation: 15%
- Test: 15%

Splitting will occur at the repository/module boundary rather than at the individual code entity level. All code entities belonging to the same file or repository will be assigned to the same partition.

### Leakage Risk Explanation
If functions or classes from the same repository are split across training and evaluation sets, the model may implicitly learn stylistic or structural patterns from the training data that appear in the evaluation data. This inflates performance metrics and reduces generalization. To prevent this, entire repositories or modules are kept isolated during splitting.

### Split Enforcement Rules
- No code entity may appear in more than one dataset split.
- Repository and file identifiers will be tracked.
- Split mapping will be stored as metadata for reproducibility.


## Candidate Repository Sources
The following repos are strong candidates for dataset extraction. These projects are written primarily in Python, follow established documentation conventions, and include substantial human-authored docstrings.

### Preliminery list of potential repositories
- Numpy
- Pandas
- Requests
- Flask
- FastAPI
- Scikit-learn
- Scrapy
- Apache Airflow
- Celery
- Matplotlib
- Pytorch (selected Python modules only)
- Click (CLI utilities)

## Licensing Compliance Requirements
Only repositories with permissive open-source licenses will be included in the dataset.
Accepted license categories:
- MIT
- Apache 2.0
- BSD-2-Clause
- BSD-3-Clause

Excluded licenses due to strong copyleft restrictions:
- GPL family
- AGPL
- LGPL (conditional exclusion depending on linking and redistribution requirements)

License metadata shall be recorded for each repository used. The ingestion pipeline will verify and store license information to ensure traceability and prevent future compliance risk.
